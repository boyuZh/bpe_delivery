{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "signed_time_key = \"Business Time\"\n",
    "order_no_key = \"Business Order NO.\"\n",
    "bill_title = \"Billing Title\"\n",
    "receiver_key = \"Driver's name\"\n",
    "receiver_code = \"Driver Code\"\n",
    "zone_key = \"destination zone\"\n",
    "fee_key = \"Excluding tax amount\"\n",
    "post_code_key = \"Postal Code\"\n",
    "weight_key = \"CW\"\n",
    "verify_remark_key = \"Verify Remark\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# signed_time_key = '签收时间\\nDelivery Time'\n",
    "# order_no_key = '运单号\\nTracking Number'\n",
    "# receiver_key = '收派员\\nDriver'\n",
    "# weight_key = '商家上传重量\\nVendor Uploaded Weight'\n",
    "# post_code_key = '邮编\\nPostcode'\n",
    "# fee_key = '计费\\nCharges'\n",
    "# verify_remark_key = \"备注\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# signed_time_key = \"业务时间/Business Time\"\n",
    "# order_no_key = \"业务单号/Business Order NO.\"\n",
    "# bill_title = \"计费科目/Billing Title\"\n",
    "# receiver_key = \"司机名称/Driver's name\"\n",
    "# fee_key = \"不含税金额/Excluding tax amount\"\n",
    "# post_code_key = \"派件省份/Delivery Province\"\n",
    "# weight_key = \"重量/weight\"\n",
    "# verify_remark_key = \"审批备注/Verify Remark\"\n",
    "# city_key = \"派件城市/Delivery City\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Boyu\\anaconda3\\envs\\py311\\Lib\\site-packages\\openpyxl\\styles\\stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    }
   ],
   "source": [
    "# folder_path = r\"C:\\Users\\alice\\Desktop\\最新数据\\iMile\\20250407-20250413-extra\"\n",
    "folder_path = r\"D:\\Projects\\transport\\raw_bill\\week19\"\n",
    "\n",
    "# folder_path = r\"C:\\Users\\alice\\Desktop\\202504\\0407-0413\\SYD\"\n",
    "\n",
    "# 判断folder_path是否是文件夹\n",
    "if os.path.isdir(folder_path):\n",
    "    file_paths = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith('.xlsx') and not f.startswith('~$')]\n",
    "\n",
    "    raw_sheets = []\n",
    "\n",
    "    for file_path in file_paths:\n",
    "        rs = pd.read_excel(file_path, sheet_name=\"sheet1\") # , usecols=[signed_time_key, order_no_key, bill_title, receiver_key, fee_key, post_code_key, weight_key, verify_remark_key]\n",
    "        raw_sheets.append(rs)\n",
    "\n",
    "    full_sheet = pd.concat(raw_sheets)\n",
    "else:\n",
    "    full_sheet = pd.read_excel(folder_path, sheet_name=\"sheet1\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_sheet = full_sheet[full_sheet[bill_title]!='丢件/损失赔偿']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "本周总单数为 49388\n"
     ]
    }
   ],
   "source": [
    "print(\"本周总单数为\", full_sheet[order_no_key].nunique())\n",
    "# full_sheet[order_no_key].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_sheet = full_sheet[full_sheet[verify_remark_key]!='adjustBill']\n",
    "adjust_sheet = full_sheet[full_sheet[verify_remark_key]=='adjustBill']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49180, 48)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "origin_sheet.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(802, 48)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjust_sheet.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the records where order_no_key that in adjust_sheet but not in origin_sheet\n",
    "extra_drivers = adjust_sheet[~adjust_sheet[order_no_key].isin(origin_sheet[order_no_key])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208, 48)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra_drivers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra_drivers.to_csv(\"extra_drivers.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_sheet = pd.concat([origin_sheet, extra_drivers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjust_sheet = adjust_sheet[~adjust_sheet[order_no_key].isin(extra_drivers[order_no_key])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "594"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjust_sheet[order_no_key].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49388, 48)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "origin_sheet.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(594, 48)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjust_sheet.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_sheet = pd.merge(origin_sheet, adjust_sheet, how='left', left_on=[order_no_key], right_on=[order_no_key], suffixes=('', '_adjust'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_sheet.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_sheet['fee_after_adjust'] = merge_sheet[fee_key] + merge_sheet[fee_key + '_adjust']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49388, 96)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_sheet.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fee_after_adjust\n",
      " 2.1    26144\n",
      " 2.2    15471\n",
      " 2.0     4365\n",
      " 2.3     1942\n",
      " 5.0      686\n",
      " 4.0      418\n",
      "-0.2      208\n",
      " 8.0      154\n",
      "Name: count, dtype: int64\n",
      "排除丢包前总价 108427.6\n"
     ]
    }
   ],
   "source": [
    "vc = merge_sheet['fee_after_adjust'].value_counts()\n",
    "total = (vc.index * vc).sum()\n",
    "print(vc)\n",
    "print(\"排除丢包前总价\", total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_sheet['fee_after_adjust'] = merge_sheet['fee_after_adjust'].apply(lambda x: round(x, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "fee_key = 'fee_after_adjust'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 处理撤销订单"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "revoke_sheet = merge_sheet[(merge_sheet[fee_key]<0) & (merge_sheet[verify_remark_key]!='adjustBill')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in revoke_sheet.iterrows():\n",
    "    revoke_order_no = row[order_no_key]\n",
    "    revoke_receiver = row[receiver_key]\n",
    "    # 寻找mergesheet中order_no_key为revoke_order_no, 并且receiver_key与revoke_receiver相同的行\n",
    "    revoke_rows = merge_sheet[(merge_sheet[order_no_key] == revoke_order_no) & (merge_sheet[receiver_key] == revoke_receiver)]\n",
    "    # 将找到结果中fee_key为负数的行去掉，也将fee_key为正数，且绝对值和去掉的负数相同的行去掉等量的行数\n",
    "    # 拆分正负fee\n",
    "    negative_fees = revoke_rows[revoke_rows[fee_key] < 0]\n",
    "    positive_fees = revoke_rows[revoke_rows[fee_key] > 0].copy()\n",
    "\n",
    "    # 标记已删除的index\n",
    "    indexes_to_drop = set(negative_fees.index)\n",
    "\n",
    "    for neg_idx, neg_row in negative_fees.iterrows():\n",
    "        abs_val = abs(neg_row[fee_key])\n",
    "        # 从正fee中找匹配的金额\n",
    "        matching_rows = positive_fees[positive_fees[fee_key] == abs_val]\n",
    "        if not matching_rows.empty:\n",
    "            # 删除第一个匹配的正数行\n",
    "            match_idx = matching_rows.index[0]\n",
    "            indexes_to_drop.add(match_idx)\n",
    "            positive_fees.drop(index=match_idx, inplace=True)\n",
    "\n",
    "    # 从 merge_sheet 中删除这些行\n",
    "    merge_sheet.drop(index=indexes_to_drop, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "警告！有数据没有派送员信息！数量：0\n"
     ]
    }
   ],
   "source": [
    "if len(merge_sheet[merge_sheet[receiver_key]==0]) > 0:\n",
    "    print(f\"警告！有数据没有派送员信息！数量：{len(merge_sheet[merge_sheet[receiver_key].isnull()])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "post_region\n",
       "2    25868\n",
       "4    23312\n",
       "0      208\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_sheet['post_region'] = merge_sheet[post_code_key].apply(lambda x: str(x)[0])\n",
    "merge_sheet['post_region'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name_sheet = pd.read_csv('data/name_sheet2.csv')\n",
    "city_name = input(\"请输入城市名称 (例如: SYD): \").upper()\n",
    "if city_name.upper() == \"SYD\":\n",
    "    name_sheet_path = 'data/name_sheet_syd.csv'\n",
    "    post_prefix = \"2\"\n",
    "    state_name = \"New South Wales\"\n",
    "elif city_name.upper() == \"ADL\":\n",
    "    name_sheet_path = 'data/name_sheet_ade.csv'\n",
    "    post_prefix = \"5\"\n",
    "    state_name = \"South Australia\"\n",
    "elif city_name.upper() == \"BNE\":\n",
    "    name_sheet_path = 'data/name_sheet_bne.csv'\n",
    "    post_prefix = \"4\"\n",
    "    state_name = \"Queensland\"\n",
    "else:\n",
    "    print(f\"未找到城市 {city_name} 对应的name_sheet文件，将使用默认文件\")\n",
    "    name_sheet_path = 'data/name_sheet2.csv'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_sheet = pd.read_csv(name_sheet_path)\n",
    "merge_sheet[post_code_key] = merge_sheet[post_code_key].astype(str)\n",
    "\n",
    "if post_code_key == \"Postal Code\":\n",
    "    raw_sheet = merge_sheet[merge_sheet[post_code_key].str.startswith(post_prefix)]\n",
    "else:\n",
    "    raw_sheet = merge_sheet[merge_sheet[post_code_key]==state_name]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23312, 97)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_sheet.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 时间格式为2025-04-13 16:05:59，需要提取日期\n",
    "\n",
    "dates = raw_sheet[signed_time_key].apply(lambda x: str(x)[:10]).unique()\n",
    "dates = np.sort(dates)\n",
    "dates = [str(date)[:10] for date in dates]\n",
    "folder_name = \"_\".join([dates[0], dates[-1]])\n",
    "project_path = os.path.join(\"output\", city_name, folder_name)\n",
    "project_cache_path = os.path.join(project_path, \"cache\")\n",
    "os.makedirs(project_path, exist_ok=True)\n",
    "os.makedirs(project_cache_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_columns = [signed_time_key, order_no_key, bill_title, receiver_key, post_code_key, zone_key, weight_key, fee_key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_sheet[table_columns].to_csv(f'{project_path}/raw_content.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 获取当周汇总数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "fees = raw_sheet[fee_key].unique()\n",
    "fees.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_sheet = raw_sheet[raw_sheet[fee_key] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_sheet = raw_sheet[fee_key].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary_sheet = summary_sheet[summary_sheet.index > 0]\n",
    "\n",
    "summary_sheet.name = '数量'\n",
    "\n",
    "new_data = pd.Series([summary_sheet.sum()], index=['Total'], name='数量')  # 新行数据\n",
    "summary_sheet = pd.concat([summary_sheet, new_data])  # 使用 pd.concat 添加新行\n",
    "summary_sheet.index.name = '单价'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "单价\n",
       "2.1      23055\n",
       "5.0        159\n",
       "8.0         98\n",
       "Total    23312\n",
       "Name: 数量, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_sheet.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_sheet.to_csv(f'{project_path}/week_summary.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 获取每位派送员派送详情"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_person_sum = raw_sheet[receiver_key].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_person_sum.name = '总数'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_person_sum = pd.DataFrame(per_person_sum)\n",
    "per_person_sum = per_person_sum.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# 定义函数，提取公司简称、账号 ID 和账号名称\n",
    "def extract_account_info(account_str):\n",
    "    match = re.match(r\"^([A-Z]+(?:-[A-Z]+)*)-(\\w+)-(.+)$\", account_str)\n",
    "    if match:\n",
    "        company_short = match.group(1)\n",
    "        account_id = match.group(2)\n",
    "        account_name = match.group(3)\n",
    "        return company_short, account_id, account_name\n",
    "    return None, None, account_str  # 仅有姓名时，填充 None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# per_person_sum['name_id'] = [\"-\".join(x.split(\"-\")[:2]) for x in per_person_sum.index.tolist()]\n",
    "per_person_sum[['company_short', 'account_id', 'account_name']] = per_person_sum[receiver_key].apply(lambda x: pd.Series(extract_account_info(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 找到新增的名字\n",
    "name_sheet[['company_short', 'account_id', 'account_name']] = name_sheet['account'].apply(lambda x: pd.Series(extract_account_info(x)))\n",
    "per_person_sum[\"account_id_name\"] = per_person_sum.apply(lambda row: \n",
    "    f\"{row['account_id']}-{row['account_name']}\" if row[\"account_id\"] else row[\"account_name\"], axis=1)\n",
    "per_person_sum['account_name'] = per_person_sum['account_name'].apply(lambda x: x.strip())\n",
    "\n",
    "name_sheet[\"account_id_name\"] = name_sheet.apply(lambda row: \n",
    "    f\"{row['account_id']}-{row['account_name']}\" if row[\"account_id\"] else row[\"account_name\"], axis=1)\n",
    "\n",
    "name_sheet['account_name'] = name_sheet['account_name'].apply(lambda x: x.strip())\n",
    "\n",
    "\n",
    "dedup_key = 'account_name'\n",
    "\n",
    "duplicate_mask = name_sheet.duplicated(subset=[dedup_key], keep=False)\n",
    "if duplicate_mask.any():\n",
    "    # 获取所有重复的记录\n",
    "    duplicates = name_sheet[duplicate_mask].copy()\n",
    "    \n",
    "    # 按account_id_name分组，对每组进行处理\n",
    "    for account_id_name, group in duplicates.groupby(dedup_key):\n",
    "        if len(group) > 1:  # 如果有重复记录\n",
    "            # 检查是否有BPE记录\n",
    "            bpe_record = group[group['company_short'] == 'BPE']\n",
    "            if not bpe_record.empty:\n",
    "                # 如果有BPE记录，删除其他记录\n",
    "                name_sheet = name_sheet[~((name_sheet[dedup_key] == account_id_name) & \n",
    "                                        (name_sheet['company_short'] != 'BPE'))]\n",
    "            else:\n",
    "                # 如果没有BPE记录，保留第一条记录\n",
    "                name_sheet = name_sheet[~((name_sheet[dedup_key] == account_id_name) & \n",
    "                                        (name_sheet.index != group.index[0]))]\n",
    "\n",
    "\n",
    "new_names_id = set(per_person_sum[dedup_key].tolist()) - set(name_sheet[dedup_key].tolist())\n",
    "new_names_id = list(new_names_id)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 添加到name_sheet\n",
    "if new_names_id:  # only proceed if there are new names\n",
    "    new_names = []\n",
    "    for name_id in new_names_id:\n",
    "        # Get the full name from per_person_sum DataFrame\n",
    "        new_person_record = per_person_sum[per_person_sum[dedup_key]==name_id]\n",
    "        company_short, account_id, account_name = extract_account_info(new_person_record[receiver_key].values[0])\n",
    "        new_names.append({\n",
    "            'account': new_person_record[receiver_key].values[0],\n",
    "            'company_short': company_short,\n",
    "            'account_id': account_id,\n",
    "            'account_name': account_name\n",
    "        })\n",
    "    \n",
    "    new_name_sheet = pd.DataFrame(new_names)\n",
    "    name_sheet = pd.concat([name_sheet, new_name_sheet], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_sheet['account'].drop_duplicates().to_csv(name_sheet_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account</th>\n",
       "      <th>company_short</th>\n",
       "      <th>account_id</th>\n",
       "      <th>account_name</th>\n",
       "      <th>account_id_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BNE-BPE-5500-Dipak BUDHATHOKI</td>\n",
       "      <td>BNE-BPE</td>\n",
       "      <td>5500</td>\n",
       "      <td>Dipak BUDHATHOKI</td>\n",
       "      <td>5500-Dipak BUDHATHOKI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BNE-BPE-5501-BILAL MUHAMMAD</td>\n",
       "      <td>BNE-BPE</td>\n",
       "      <td>5501</td>\n",
       "      <td>BILAL MUHAMMAD</td>\n",
       "      <td>5501-BILAL MUHAMMAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BNE-BPE-5502-Bikalpa DAWADI</td>\n",
       "      <td>BNE-BPE</td>\n",
       "      <td>5502</td>\n",
       "      <td>Bikalpa DAWADI</td>\n",
       "      <td>5502-Bikalpa DAWADI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BNE-BPE-5503-Hoi Yee POW</td>\n",
       "      <td>BNE-BPE</td>\n",
       "      <td>5503</td>\n",
       "      <td>Hoi Yee POW</td>\n",
       "      <td>5503-Hoi Yee POW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BNE-BPE-5504-Chu Feng LEE</td>\n",
       "      <td>BNE-BPE</td>\n",
       "      <td>5504</td>\n",
       "      <td>Chu Feng LEE</td>\n",
       "      <td>5504-Chu Feng LEE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         account company_short account_id      account_name  \\\n",
       "0  BNE-BPE-5500-Dipak BUDHATHOKI       BNE-BPE       5500  Dipak BUDHATHOKI   \n",
       "1    BNE-BPE-5501-BILAL MUHAMMAD       BNE-BPE       5501    BILAL MUHAMMAD   \n",
       "2    BNE-BPE-5502-Bikalpa DAWADI       BNE-BPE       5502    Bikalpa DAWADI   \n",
       "3       BNE-BPE-5503-Hoi Yee POW       BNE-BPE       5503       Hoi Yee POW   \n",
       "4      BNE-BPE-5504-Chu Feng LEE       BNE-BPE       5504      Chu Feng LEE   \n",
       "\n",
       "         account_id_name  \n",
       "0  5500-Dipak BUDHATHOKI  \n",
       "1    5501-BILAL MUHAMMAD  \n",
       "2    5502-Bikalpa DAWADI  \n",
       "3       5503-Hoi Yee POW  \n",
       "4      5504-Chu Feng LEE  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_sheet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23312"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_person_sum['总数'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_join_sheet = pd.merge(name_sheet, per_person_sum, left_on=dedup_key, right_on=dedup_key, how='left', suffixes=('_obs', ''), sort=False)\n",
    "name_join_sheet.fillna(0, inplace=True)\n",
    "name_join_sheet['总数'] = name_join_sheet['总数'].astype(int) # 将总数列转换为整数\n",
    "# name_sheet = name_sheet.to_json(orient='records')\n",
    "# name_sheet = json.loads(name_sheet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总数匹配: 23312 == 23312\n"
     ]
    }
   ],
   "source": [
    "if name_join_sheet['总数'].sum() != summary_sheet.sum()//2:\n",
    "    print(f\"总数不匹配: {name_join_sheet['总数'].sum()} != {summary_sheet.sum()//2}\")\n",
    "    raise ValueError(f\"总数不匹配: {name_join_sheet['总数'].sum()} != {summary_sheet.sum()//2}\")\n",
    "else:\n",
    "    print(f\"总数匹配: {name_join_sheet['总数'].sum()} == {summary_sheet.sum()//2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(counts.to_json(force_ascii=False))\n",
    "# signed_time_key = None\n",
    "# receiver_key = None\n",
    "# fee_key = None\n",
    "raw_sheet[signed_time_key] = raw_sheet[signed_time_key].apply(lambda x: str(x)[:10])\n",
    "counts = raw_sheet.groupby([receiver_key, signed_time_key, fee_key]).size().reset_index(name='记录数')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 转换为嵌套 JSON\n",
    "nested_json = (\n",
    "    counts.reset_index()  # 将 MultiIndex 转为普通列\n",
    "    .groupby(receiver_key)  # 按收派员名字分组\n",
    "    .apply(lambda x: x.groupby(signed_time_key)  # 在组内按签收时间分组\n",
    "           .apply(lambda y: y.set_index(fee_key)['记录数'].to_dict())  # 将计费和对应数量转为字典\n",
    "           .to_dict())  # 将签收时间分组转为字典\n",
    "    .to_dict()  # 将收派员编号分组转为字典\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_join_sheet['data'] = name_join_sheet[receiver_key].apply(lambda x: nested_json.get(x, {}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns = [\"序号\", \"编号\", \"ACCOUNT\"]\n",
    "columns = [\"序号\", \"ACCOUNT\"]\n",
    "sub_columns = [\"\"] * len(columns)\n",
    "# 定义表头\n",
    "for d in dates:\n",
    "    columns.append(d)\n",
    "    columns.extend([\"\"] * (len(fees) - 1))\n",
    "\n",
    "    sub_columns.extend(fees)\n",
    "\n",
    "columns.append(\"Total\")\n",
    "sub_columns.append(\"\")\n",
    "# 创建多级表头\n",
    "header = pd.MultiIndex.from_tuples(list(zip(columns, sub_columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = []\n",
    "\n",
    "for idx, person in name_join_sheet.iterrows():\n",
    "    data = [idx+1, person['account']]\n",
    "    for d in dates:\n",
    "        if d in person['data']:\n",
    "            for f in fees:\n",
    "                if f in person['data'][d]:\n",
    "                    data.append(person['data'][d].get(f, \"\"))\n",
    "                else:\n",
    "                    data.append(\"\")\n",
    "        else:\n",
    "            data.extend([\"\"] * len(fees))\n",
    "    data.append(person['总数'])\n",
    "    full_data.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 添加汇总行\n",
    "total_row = [\"Total\", \"总计\"]\n",
    "total_by_date_fee = {}  # 用于存储每个日期和费用类型的总和\n",
    "\n",
    "# 初始化汇总数据结构\n",
    "for d in dates:\n",
    "    total_by_date_fee[d] = {f: 0 for f in fees}\n",
    "\n",
    "# 计算每个日期和费用类型的总和\n",
    "for person in name_join_sheet.itertuples():\n",
    "    for d in dates:\n",
    "        if hasattr(person, 'data') and d in person.data:\n",
    "            for f in fees:\n",
    "                if f in person.data[d]:\n",
    "                    total_by_date_fee[d][f] += person.data[d][f]\n",
    "\n",
    "# 构建汇总行数据\n",
    "for d in dates:\n",
    "    for f in fees:\n",
    "        total_row.append(total_by_date_fee[d][f])\n",
    "\n",
    "# 添加总计数量\n",
    "total_row.append(name_join_sheet['总数'].sum())\n",
    "\n",
    "# 将汇总行添加到full_data\n",
    "full_data.append(total_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建 DataFrame\n",
    "df = pd.DataFrame(full_data, columns=header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件已保存至 output\\BNE\\2025-05-05_2025-05-11/per_person_details.xlsx\n"
     ]
    }
   ],
   "source": [
    "from openpyxl import load_workbook\n",
    "\n",
    "df.to_excel(f\"{project_cache_path}/output.xlsx\", index=True)\n",
    "# 加载并移除空行\n",
    "wb = load_workbook(f\"{project_cache_path}/output.xlsx\")\n",
    "ws = wb.active\n",
    "\n",
    "# 删除空行（通常是第3行）\n",
    "ws.delete_rows(3)\n",
    "# ws.delete_cols(0)\n",
    "\n",
    "# 保存调整后的文件\n",
    "wb.save(f\"{project_path}/per_person_details.xlsx\")\n",
    "print(f\"文件已保存至 {project_path}/per_person_details.xlsx\")\n",
    "wb.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
